# ğŸ“Š ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿä½¿ç”¨æŒ‡å—

## ğŸ¯ ç³»ç»Ÿæ¦‚è§ˆ

æœ¬æ–‡æ¡£ä»‹ç» Figma Frame Faithful é¡¹ç›®çš„å®Œæ•´ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿï¼ŒåŒ…æ‹¬éƒ¨ç½²ã€é…ç½®å’Œä½¿ç”¨æ–¹æ³•ã€‚

### ğŸ—ï¸ æ¶æ„ç»„ä»¶

#### ç›‘æ§ç³»ç»Ÿ (Monitoring)
- **Prometheus** - æŒ‡æ ‡æ”¶é›†å’Œå­˜å‚¨
- **Grafana** - å¯è§†åŒ–ä»ªè¡¨æ¿
- **AlertManager** - å‘Šè­¦ç®¡ç†å’Œé€šçŸ¥
- **Node Exporter** - èŠ‚ç‚¹æŒ‡æ ‡æ”¶é›†

#### æ—¥å¿—ç³»ç»Ÿ (Logging)
- **Elasticsearch** - æ—¥å¿—å­˜å‚¨å’Œæœç´¢
- **Logstash** - æ—¥å¿—å¤„ç†å’Œè½¬æ¢
- **Kibana** - æ—¥å¿—å¯è§†åŒ–å’Œåˆ†æ
- **Filebeat** - æ—¥å¿—æ”¶é›†ä»£ç†

## ğŸš€ å¿«é€Ÿéƒ¨ç½²

### è‡ªåŠ¨åŒ–éƒ¨ç½²

ä½¿ç”¨æä¾›çš„éƒ¨ç½²è„šæœ¬ä¸€é”®éƒ¨ç½²æ•´ä¸ªç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿï¼š

```bash
# éƒ¨ç½²å®Œæ•´çš„ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ
./scripts/deploy-monitoring.sh

# ä»…éƒ¨ç½²ç›‘æ§ç³»ç»Ÿ
./scripts/deploy-monitoring.sh --monitoring-only

# ä»…éƒ¨ç½²æ—¥å¿—ç³»ç»Ÿ
./scripts/deploy-monitoring.sh --logging-only

# å¯ç”¨Ingresså¤–éƒ¨è®¿é—®
./scripts/deploy-monitoring.sh --enable-ingress
```

### æ‰‹åŠ¨éƒ¨ç½²

å¦‚æœéœ€è¦æ›´ç²¾ç»†çš„æ§åˆ¶ï¼Œå¯ä»¥æ‰‹åŠ¨éƒ¨ç½²å„ä¸ªç»„ä»¶ï¼š

```bash
# 1. åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace monitoring
kubectl create namespace logging

# 2. éƒ¨ç½²ç›‘æ§ç³»ç»Ÿ
kubectl apply -f k8s/monitoring/prometheus.yaml
kubectl apply -f k8s/monitoring/grafana.yaml
kubectl apply -f k8s/monitoring/alertmanager.yaml
kubectl apply -f k8s/monitoring/node-exporter.yaml

# 3. éƒ¨ç½²æ—¥å¿—ç³»ç»Ÿ
kubectl apply -f k8s/logging/elasticsearch.yaml
kubectl apply -f k8s/logging/logstash.yaml
kubectl apply -f k8s/logging/kibana.yaml
kubectl apply -f k8s/logging/filebeat.yaml
```

## ğŸ” ç³»ç»Ÿè®¿é—®

### æœ¬åœ°è®¿é—® (ç«¯å£è½¬å‘)

```bash
# Prometheus (ç›‘æ§æ•°æ®)
kubectl port-forward -n monitoring svc/prometheus 9090:9090
# è®¿é—®: http://localhost:9090

# Grafana (ç›‘æ§ä»ªè¡¨æ¿)
kubectl port-forward -n monitoring svc/grafana 3000:3000
# è®¿é—®: http://localhost:3000
# é»˜è®¤è´¦å·: admin / admin123!@#

# AlertManager (å‘Šè­¦ç®¡ç†)
kubectl port-forward -n monitoring svc/alertmanager 9093:9093
# è®¿é—®: http://localhost:9093

# Kibana (æ—¥å¿—åˆ†æ)
kubectl port-forward -n logging svc/kibana 5601:5601
# è®¿é—®: http://localhost:5601

# Elasticsearch (ç›´æ¥APIè®¿é—®)
kubectl port-forward -n logging svc/elasticsearch 9200:9200
# è®¿é—®: http://localhost:9200
```

### ç”Ÿäº§ç¯å¢ƒè®¿é—®

å¦‚æœå¯ç”¨äº†Ingressï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹åŸŸåè®¿é—®ï¼š

- Grafana: `https://grafana.figma-frame-faithful.com`
- Kibana: `https://kibana.figma-frame-faithful.com`

## ğŸ“Š Grafanaä»ªè¡¨æ¿

### é¢„é…ç½®ä»ªè¡¨æ¿

ç³»ç»Ÿé¢„ç½®äº†ä»¥ä¸‹ä»ªè¡¨æ¿ï¼š

1. **Kubernetesé›†ç¾¤ç›‘æ§**
   - èŠ‚ç‚¹çŠ¶æ€å’Œèµ„æºä½¿ç”¨
   - PodçŠ¶æ€åˆ†å¸ƒ
   - ç½‘ç»œæµé‡ç›‘æ§

2. **åº”ç”¨ç¨‹åºç›‘æ§**
   - HTTPè¯·æ±‚ç»Ÿè®¡
   - å“åº”æ—¶é—´åˆ†æ
   - é”™è¯¯ç‡ç›‘æ§
   - Podèµ„æºä½¿ç”¨

3. **åŸºç¡€è®¾æ–½ç›‘æ§**
   - CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨ç‡
   - ç½‘ç»œI/Oç»Ÿè®¡
   - ç³»ç»Ÿè´Ÿè½½ç›‘æ§

### è‡ªå®šä¹‰ä»ªè¡¨æ¿

åœ¨Grafanaä¸­åˆ›å»ºè‡ªå®šä¹‰ä»ªè¡¨æ¿ï¼š

1. ç™»å½•Grafana (admin/admin123!@#)
2. ç‚¹å‡» "+" â†’ "Dashboard"
3. æ·»åŠ Panelï¼Œé€‰æ‹©æ•°æ®æº "Prometheus"
4. ç¼–å†™PromQLæŸ¥è¯¢è¯­å¥

#### å¸¸ç”¨PromQLæŸ¥è¯¢

```promql
# CPUä½¿ç”¨ç‡
100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# å†…å­˜ä½¿ç”¨ç‡
(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100

# HTTPè¯·æ±‚ç‡
rate(nginx_ingress_controller_requests_total[5m])

# åº”ç”¨å“åº”æ—¶é—´ (95th percentile)
histogram_quantile(0.95, rate(nginx_ingress_controller_request_duration_seconds_bucket[5m]))

# Podé‡å¯æ¬¡æ•°
increase(kube_pod_container_status_restarts_total[1h])
```

## ğŸ“‹ æ—¥å¿—åˆ†æ

### Kibanaä½¿ç”¨æŒ‡å—

#### åˆ›å»ºç´¢å¼•æ¨¡å¼

1. æ‰“å¼€Kibana â†’ Management â†’ Stack Management â†’ Index Patterns
2. åˆ›å»ºä»¥ä¸‹ç´¢å¼•æ¨¡å¼ï¼š
   - `application-logs-*` (åº”ç”¨æ—¥å¿—)
   - `nginx-logs-*` (Nginxè®¿é—®æ—¥å¿—)
   - `kubernetes-logs-*` (Kubernetesç³»ç»Ÿæ—¥å¿—)

#### æ—¥å¿—æŸ¥è¯¢è¯­æ³•

```javascript
// æŸ¥è¯¢é”™è¯¯æ—¥å¿—
log_level: "error" OR has_error: true

// æŸ¥è¯¢ç‰¹å®šæ—¶é—´æ®µçš„æ—¥å¿—
@timestamp: [2024-01-01 TO 2024-01-02]

// æŸ¥è¯¢ç‰¹å®šPodçš„æ—¥å¿—
kubernetes.pod.name: "figma-frame-faithful-*"

// æŸ¥è¯¢HTTPé”™è¯¯
status_category: "server_error" OR response: [500 TO 599]

// æŸ¥è¯¢æ€§èƒ½æ…¢çš„è¯·æ±‚
duration: [1000 TO *]

// ç»„åˆæŸ¥è¯¢
log_level: "error" AND kubernetes.namespace: "production" AND @timestamp: [now-1h TO now]
```

### æ—¥å¿—èšåˆå’Œåˆ†æ

#### åˆ›å»ºå¯è§†åŒ–å›¾è¡¨

1. **é”™è¯¯è¶‹åŠ¿å›¾**
   - ç´¢å¼•: `application-logs-*`
   - å›¾è¡¨ç±»å‹: Line Chart
   - Xè½´: @timestamp (Date Histogram)
   - Yè½´: Count of documents
   - è¿‡æ»¤å™¨: `has_error: true`

2. **HTTPçŠ¶æ€ç åˆ†å¸ƒ**
   - ç´¢å¼•: `nginx-logs-*`
   - å›¾è¡¨ç±»å‹: Pie Chart
   - åˆ†å‰²: response (Terms)
   - æŒ‡æ ‡: Count

3. **æ€§èƒ½çƒ­åŠ›å›¾**
   - ç´¢å¼•: `application-logs-*`
   - å›¾è¡¨ç±»å‹: Heatmap
   - Xè½´: @timestamp
   - Yè½´: duration
   - å€¼: Count

## ğŸš¨ å‘Šè­¦é…ç½®

### AlertManagerå‘Šè­¦è§„åˆ™

ç³»ç»Ÿé¢„é…ç½®äº†ä»¥ä¸‹å‘Šè­¦è§„åˆ™ï¼š

#### åŸºç¡€è®¾æ–½å‘Šè­¦

```yaml
# èŠ‚ç‚¹å®•æœº
- alert: NodeDown
  expr: up{job="node-exporter"} == 0
  for: 5m

# é«˜CPUä½¿ç”¨ç‡
- alert: NodeHighCPU
  expr: 100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
  for: 10m

# é«˜å†…å­˜ä½¿ç”¨ç‡
- alert: NodeHighMemory
  expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
  for: 5m
```

#### åº”ç”¨å‘Šè­¦

```yaml
# Podå´©æºƒå¾ªç¯
- alert: PodCrashLooping
  expr: rate(kube_pod_container_status_restarts_total[10m]) > 0
  for: 5m

# é«˜å“åº”æ—¶é—´
- alert: HighResponseTime
  expr: histogram_quantile(0.95, rate(nginx_ingress_controller_request_duration_seconds_bucket[5m])) > 2
  for: 10m

# é«˜é”™è¯¯ç‡
- alert: HighErrorRate
  expr: rate(nginx_ingress_controller_requests_total{status=~"5.."}[5m]) / rate(nginx_ingress_controller_requests_total[5m]) * 100 > 5
  for: 5m
```

### è‡ªå®šä¹‰å‘Šè­¦è§„åˆ™

åœ¨`k8s/monitoring/prometheus.yaml`ä¸­æ·»åŠ è‡ªå®šä¹‰è§„åˆ™ï¼š

```yaml
groups:
- name: custom.rules
  rules:
  - alert: CustomAlert
    expr: your_metric > threshold
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "è‡ªå®šä¹‰å‘Šè­¦"
      description: "è¯¦ç»†æè¿°"
```

### é€šçŸ¥é…ç½®

ç¼–è¾‘`k8s/monitoring/alertmanager.yaml`é…ç½®é€šçŸ¥æ¸ é“ï¼š

#### é‚®ä»¶é€šçŸ¥

```yaml
email_configs:
- to: 'admin@figma-frame-faithful.com'
  subject: 'ğŸš¨ å‘Šè­¦é€šçŸ¥'
  body: |
    å‘Šè­¦: {{ .Annotations.summary }}
    æè¿°: {{ .Annotations.description }}
```

#### Slacké€šçŸ¥

```yaml
slack_configs:
- channel: '#alerts'
  title: 'ğŸš¨ ç³»ç»Ÿå‘Šè­¦'
  text: |
    *å‘Šè­¦:* {{ .Annotations.summary }}
    *æè¿°:* {{ .Annotations.description }}
```

#### é’‰é’‰é€šçŸ¥

```yaml
webhook_configs:
- url: 'https://oapi.dingtalk.com/robot/send?access_token=YOUR_TOKEN'
  send_resolved: true
```

## ğŸ”§ ç³»ç»Ÿç»´æŠ¤

### ç›‘æ§ç³»ç»Ÿå¥åº·æ£€æŸ¥

```bash
# æ£€æŸ¥æ‰€æœ‰ç›‘æ§ç»„ä»¶çŠ¶æ€
kubectl get pods -n monitoring
kubectl get pods -n logging

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
kubectl get svc -n monitoring
kubectl get svc -n logging

# æ£€æŸ¥å­˜å‚¨ä½¿ç”¨æƒ…å†µ
kubectl get pvc -n monitoring
kubectl get pvc -n logging

# æŸ¥çœ‹èµ„æºä½¿ç”¨æƒ…å†µ
kubectl top pods -n monitoring
kubectl top pods -n logging
```

### æ•°æ®ä¿ç•™ç­–ç•¥

#### Prometheusæ•°æ®ä¿ç•™

é»˜è®¤ä¿ç•™30å¤©ï¼Œå¯åœ¨é…ç½®ä¸­ä¿®æ”¹ï¼š

```yaml
args:
- '--storage.tsdb.retention.time=30d'
- '--storage.tsdb.retention.size=90GB'
```

#### Elasticsearchæ•°æ®ä¿ç•™

åˆ›å»ºILMç­–ç•¥è‡ªåŠ¨ç®¡ç†ç´¢å¼•ç”Ÿå‘½å‘¨æœŸï¼š

```json
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "10GB",
            "max_age": "7d"
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "delete": {
        "min_age": "30d"
      }
    }
  }
}
```

### æ€§èƒ½ä¼˜åŒ–

#### Prometheusæ€§èƒ½è°ƒä¼˜

```yaml
# å¢åŠ å†…å­˜é™åˆ¶
resources:
  limits:
    memory: "8Gi"

# è°ƒæ•´æŠ“å–é—´éš”
global:
  scrape_interval: 30s
  evaluation_interval: 30s

# å¯ç”¨å‹ç¼©
remote_write:
- url: "http://remote-storage/api/v1/write"
  compression: snappy
```

#### Elasticsearchæ€§èƒ½è°ƒä¼˜

```yaml
# JVMå †å†…å­˜è®¾ç½®
env:
- name: ES_JAVA_OPTS
  value: "-Xms4g -Xmx4g"

# ç´¢å¼•è®¾ç½®ä¼˜åŒ–
template:
  settings:
    number_of_shards: 1
    number_of_replicas: 1
    refresh_interval: "30s"
    index.codec: "best_compression"
```

### å¤‡ä»½å’Œæ¢å¤

#### Prometheusæ•°æ®å¤‡ä»½

```bash
# åˆ›å»ºå¿«ç…§
curl -XPOST http://prometheus:9090/api/v1/admin/tsdb/snapshot

# å¤åˆ¶å¿«ç…§æ•°æ®
kubectl cp monitoring/prometheus-pod:/prometheus/snapshots/snapshot-name ./backup/
```

#### Elasticsearchæ•°æ®å¤‡ä»½

```bash
# åˆ›å»ºä»“åº“
curl -X PUT "elasticsearch:9200/_snapshot/backup_repository" -H 'Content-Type: application/json' -d'
{
  "type": "fs",
  "settings": {
    "location": "/backup"
  }
}'

# åˆ›å»ºå¿«ç…§
curl -X PUT "elasticsearch:9200/_snapshot/backup_repository/snapshot_1"
```

## ğŸ” å®‰å…¨é…ç½®

### è®¤è¯å’Œæˆæƒ

#### Grafanaå®‰å…¨è®¾ç½®

```yaml
# ä¿®æ”¹é»˜è®¤å¯†ç 
env:
- name: GF_SECURITY_ADMIN_PASSWORD
  valueFrom:
    secretKeyRef:
      name: grafana-secret
      key: admin-password

# å¯ç”¨LDAPè®¤è¯
- name: GF_AUTH_LDAP_ENABLED
  value: "true"
```

#### Elasticsearchå®‰å…¨è®¾ç½®

```yaml
# å¯ç”¨X-Packå®‰å…¨
xpack.security.enabled: true

# é…ç½®TLS
xpack.security.transport.ssl.enabled: true
xpack.security.http.ssl.enabled: true
```

### ç½‘ç»œå®‰å…¨

#### ç½‘ç»œç­–ç•¥

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: monitoring-network-policy
spec:
  podSelector:
    matchLabels:
      tier: monitoring
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
```

#### TLSåŠ å¯†

ä¸ºæ‰€æœ‰ç»„ä»¶é—´é€šä¿¡å¯ç”¨TLSåŠ å¯†ï¼š

```yaml
# Prometheus TLSé…ç½®
tls_config:
  ca_file: /etc/ssl/certs/ca.crt
  cert_file: /etc/ssl/certs/client.crt
  key_file: /etc/ssl/private/client.key
```

## ğŸ“š æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

#### 1. Prometheusæ— æ³•æŠ“å–æŒ‡æ ‡

```bash
# æ£€æŸ¥ç›®æ ‡çŠ¶æ€
kubectl exec -n monitoring deployment/prometheus -- wget -qO- http://localhost:9090/api/v1/targets

# æ£€æŸ¥ç½‘ç»œè¿æ¥
kubectl exec -n monitoring deployment/prometheus -- nslookup target-service

# æ£€æŸ¥æœåŠ¡å‘ç°
kubectl get endpoints -n target-namespace
```

#### 2. Grafanaæ— æ³•è¿æ¥Prometheus

```bash
# æ£€æŸ¥æ•°æ®æºé…ç½®
kubectl exec -n monitoring deployment/grafana -- curl -s http://prometheus:9090/api/v1/query?query=up

# æ£€æŸ¥DNSè§£æ
kubectl exec -n monitoring deployment/grafana -- nslookup prometheus.monitoring.svc.cluster.local
```

#### 3. Elasticsearché›†ç¾¤çŠ¶æ€å¼‚å¸¸

```bash
# æ£€æŸ¥é›†ç¾¤å¥åº·çŠ¶æ€
kubectl exec -n logging statefulset/elasticsearch-master -- curl -s http://localhost:9200/_cluster/health

# æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€
kubectl exec -n logging statefulset/elasticsearch-master -- curl -s http://localhost:9200/_cat/nodes?v

# æ£€æŸ¥ç´¢å¼•çŠ¶æ€
kubectl exec -n logging statefulset/elasticsearch-master -- curl -s http://localhost:9200/_cat/indices?v
```

#### 4. æ—¥å¿—æ•°æ®ä¸¢å¤±

```bash
# æ£€æŸ¥FilebeatçŠ¶æ€
kubectl logs -n logging daemonset/filebeat

# æ£€æŸ¥Logstashå¤„ç†çŠ¶æ€
kubectl logs -n logging deployment/logstash

# æ£€æŸ¥Elasticsearchå­˜å‚¨
kubectl exec -n logging statefulset/elasticsearch-master -- curl -s http://localhost:9200/_cat/allocation?v
```

### æ—¥å¿—åˆ†æ

#### ç›‘æ§ç»„ä»¶æ—¥å¿—

```bash
# Prometheusæ—¥å¿—
kubectl logs -n monitoring deployment/prometheus -f

# Grafanaæ—¥å¿—
kubectl logs -n monitoring deployment/grafana -f

# Elasticsearchæ—¥å¿—
kubectl logs -n logging statefulset/elasticsearch-master -f

# Logstashæ—¥å¿—
kubectl logs -n logging deployment/logstash -f
```

#### ç³»ç»Ÿäº‹ä»¶

```bash
# æŸ¥çœ‹Podäº‹ä»¶
kubectl describe pod -n monitoring prometheus-pod-name

# æŸ¥çœ‹å‘½åç©ºé—´äº‹ä»¶
kubectl get events -n monitoring --sort-by='.lastTimestamp'

# æŸ¥çœ‹èŠ‚ç‚¹äº‹ä»¶
kubectl get events --field-selector involvedObject.kind=Node
```

## ğŸ“ˆ æ€§èƒ½ç›‘æ§æŒ‡æ ‡

### å…³é”®æ€§èƒ½æŒ‡æ ‡ (KPIs)

#### åº”ç”¨æ€§èƒ½æŒ‡æ ‡

- **å“åº”æ—¶é—´**: 95th percentile < 2ç§’
- **é”™è¯¯ç‡**: < 1%
- **å¯ç”¨æ€§**: > 99.9%
- **ååé‡**: æ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾å®š

#### åŸºç¡€è®¾æ–½æŒ‡æ ‡

- **CPUä½¿ç”¨ç‡**: < 80%
- **å†…å­˜ä½¿ç”¨ç‡**: < 85%
- **ç£ç›˜ä½¿ç”¨ç‡**: < 80%
- **ç½‘ç»œå»¶è¿Ÿ**: < 100ms

#### ç›‘æ§ç³»ç»Ÿè‡ªèº«æŒ‡æ ‡

- **Prometheusæ•°æ®æ‘„å…¥ç‡**: ç›‘æ§æ ·æœ¬æ•°/ç§’
- **Grafanaå“åº”æ—¶é—´**: < 3ç§’
- **ElasticsearchæŸ¥è¯¢æ€§èƒ½**: < 500ms
- **æ—¥å¿—å¤„ç†å»¶è¿Ÿ**: < 30ç§’

### å®¹é‡è§„åˆ’

#### å­˜å‚¨éœ€æ±‚ä¼°ç®—

```bash
# Prometheuså­˜å‚¨éœ€æ±‚ (æ¯å¤©)
# æ ·æœ¬æ•° Ã— æ ·æœ¬å¤§å° Ã— 86400ç§’ Ã· æŠ“å–é—´éš”
# ä¾‹: 10000 Ã— 1bytes Ã— 86400 Ã· 15 = 57.6MB/å¤©

# Elasticsearchå­˜å‚¨éœ€æ±‚
# æ—¥å¿—æ¡æ•° Ã— å¹³å‡æ—¥å¿—å¤§å°
# ä¾‹: 1000000 Ã— 500bytes = 500MB/å¤©
```

## ğŸ¯ æœ€ä½³å®è·µ

### ç›‘æ§æœ€ä½³å®è·µ

1. **åˆ†å±‚ç›‘æ§**: åŸºç¡€è®¾æ–½ â†’ åº”ç”¨ â†’ ä¸šåŠ¡
2. **å‘Šè­¦åˆ†çº§**: Critical â†’ Warning â†’ Info
3. **SLI/SLOè®¾å®š**: æ˜ç¡®æœåŠ¡è´¨é‡ç›®æ ‡
4. **å¯è§‚æµ‹æ€§**: æŒ‡æ ‡ + æ—¥å¿— + é“¾è·¯è¿½è¸ª

### æ—¥å¿—æœ€ä½³å®è·µ

1. **ç»“æ„åŒ–æ—¥å¿—**: ä½¿ç”¨JSONæ ¼å¼
2. **ç»Ÿä¸€æ—¥å¿—çº§åˆ«**: ERROR â†’ WARN â†’ INFO â†’ DEBUG
3. **ä¸Šä¸‹æ–‡ä¿¡æ¯**: åŒ…å«è¯·æ±‚IDã€ç”¨æˆ·IDç­‰
4. **æ•æ„Ÿä¿¡æ¯è„±æ•**: é¿å…è®°å½•å¯†ç ã€tokenç­‰

### è¿ç»´æœ€ä½³å®è·µ

1. **å®šæœŸå¤‡ä»½**: ç›‘æ§æ•°æ®å’Œé…ç½®
2. **å®¹é‡è§„åˆ’**: é¢„ä¼°å­˜å‚¨å’Œè®¡ç®—éœ€æ±‚
3. **å®‰å…¨åŠ å›º**: è®¤è¯ã€æˆæƒã€åŠ å¯†
4. **æ–‡æ¡£ç»´æŠ¤**: ä¿æŒæ–‡æ¡£æ›´æ–°

---

## ğŸ†˜ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·ï¼š

1. æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—å’Œç›‘æ§æŒ‡æ ‡
2. å‚è€ƒæœ¬æ–‡æ¡£çš„æ•…éšœæ’æŸ¥éƒ¨åˆ†
3. è”ç³»è¿ç»´å›¢é˜Ÿ: ops@figma-frame-faithful.com
4. æäº¤Issueåˆ°é¡¹ç›®ä»“åº“

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2024å¹´12æœˆ  
**ç»´æŠ¤è€…**: Figma Frame Faithful DevOps Team