# üîÑ Â§á‰ªΩÂíåÊÅ¢Â§çÁ≥ªÁªüÈÖçÁΩÆ
# ‰∏∫Áîü‰∫ßÁéØÂ¢ÉÊèê‰æõÂÖ®Èù¢ÁöÑÊï∞ÊçÆÂ§á‰ªΩÂíåÁÅæÈöæÊÅ¢Â§çËÉΩÂäõ

apiVersion: v1
kind: Namespace
metadata:
  name: backup
  labels:
    name: backup
    tier: infrastructure

---
# üìã ConfigMap - Â§á‰ªΩÈÖçÁΩÆ
apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-config
  namespace: backup
  labels:
    app: backup-system
data:
  # Â§á‰ªΩÈÖçÁΩÆÊñá‰ª∂
  backup.conf: |
    # Â§á‰ªΩÁ≥ªÁªüÈÖçÁΩÆ
    BACKUP_RETENTION_DAYS=30
    BACKUP_COMPRESSION=gzip
    BACKUP_ENCRYPTION=true
    
    # Êï∞ÊçÆÂ∫ìÂ§á‰ªΩÈÖçÁΩÆ
    DB_BACKUP_ENABLED=true
    DB_BACKUP_SCHEDULE="0 2 * * *"  # ÊØèÂ§©ÂáåÊô®2ÁÇπ
    DB_BACKUP_RETENTION=7
    
    # Â∫îÁî®Êï∞ÊçÆÂ§á‰ªΩÈÖçÁΩÆ
    APP_BACKUP_ENABLED=true
    APP_BACKUP_SCHEDULE="0 3 * * *"  # ÊØèÂ§©ÂáåÊô®3ÁÇπ
    APP_BACKUP_RETENTION=7
    
    # ÁõëÊéßÊï∞ÊçÆÂ§á‰ªΩÈÖçÁΩÆ
    MONITORING_BACKUP_ENABLED=true
    MONITORING_BACKUP_SCHEDULE="0 4 * * *"  # ÊØèÂ§©ÂáåÊô®4ÁÇπ
    MONITORING_BACKUP_RETENTION=14
    
    # ÈÖçÁΩÆÊñá‰ª∂Â§á‰ªΩ
    CONFIG_BACKUP_ENABLED=true
    CONFIG_BACKUP_SCHEDULE="0 1 * * 0"  # ÊØèÂë®Êó•ÂáåÊô®1ÁÇπ
    CONFIG_BACKUP_RETENTION=30
    
    # Â≠òÂÇ®ÈÖçÁΩÆ
    BACKUP_STORAGE_TYPE=s3
    S3_BUCKET=figma-frame-faithful-backups
    S3_REGION=us-east-1
    S3_STORAGE_CLASS=STANDARD_IA
    
    # ÈÄöÁü•ÈÖçÁΩÆ
    NOTIFICATION_ENABLED=true
    NOTIFICATION_WEBHOOK=https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK
    NOTIFICATION_EMAIL=ops@figma-frame-faithful.com

  # SupabaseÊï∞ÊçÆÂ∫ìÂ§á‰ªΩËÑöÊú¨
  backup-supabase.sh: |
    #!/bin/bash
    set -euo pipefail
    
    # ÈÖçÁΩÆÂèòÈáè
    BACKUP_NAME="supabase-backup-$(date +%Y%m%d-%H%M%S)"
    BACKUP_DIR="/tmp/backups"
    
    log() {
        echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
    }
    
    # ÂàõÂª∫Â§á‰ªΩÁõÆÂΩï
    mkdir -p "$BACKUP_DIR"
    
    log "ÂºÄÂßãSupabaseÊï∞ÊçÆÂ∫ìÂ§á‰ªΩ..."
    
    # ‰ΩøÁî®Supabase CLIËøõË°åÂ§á‰ªΩ
    if command -v supabase &> /dev/null; then
        log "‰ΩøÁî®Supabase CLIÂ§á‰ªΩ..."
        
        # Â§á‰ªΩÊï∞ÊçÆÂ∫ìÁªìÊûÑ
        supabase db dump --schema-only > "$BACKUP_DIR/${BACKUP_NAME}-schema.sql"
        
        # Â§á‰ªΩÊï∞ÊçÆ
        supabase db dump --data-only > "$BACKUP_DIR/${BACKUP_NAME}-data.sql"
        
        # Â§á‰ªΩÂ≠òÂÇ®Ê°∂Êñá‰ª∂ÔºàÂ¶ÇÊûúÊúâÔºâ
        if [[ "${BACKUP_STORAGE:-true}" == "true" ]]; then
            log "Â§á‰ªΩÂ≠òÂÇ®Ê°∂Êñá‰ª∂..."
            supabase storage ls --recursive > "$BACKUP_DIR/${BACKUP_NAME}-storage-list.txt"
        fi
        
    else
        # ‰ΩøÁî®pg_dumpÂ§á‰ªΩÔºàÂ¶ÇÊûúÊúâÁõ¥Êé•Êï∞ÊçÆÂ∫ìËÆøÈóÆÔºâ
        if [[ -n "${SUPABASE_DB_URL:-}" ]]; then
            log "‰ΩøÁî®pg_dumpÂ§á‰ªΩ..."
            pg_dump "$SUPABASE_DB_URL" --schema-only > "$BACKUP_DIR/${BACKUP_NAME}-schema.sql"
            pg_dump "$SUPABASE_DB_URL" --data-only > "$BACKUP_DIR/${BACKUP_NAME}-data.sql"
        else
            log "ERROR: Êó†Ê≥ïÊâæÂà∞Supabase CLIÊàñÊï∞ÊçÆÂ∫ìËøûÊé•‰ø°ÊÅØ"
            exit 1
        fi
    fi
    
    # ÂéãÁº©Â§á‰ªΩÊñá‰ª∂
    log "ÂéãÁº©Â§á‰ªΩÊñá‰ª∂..."
    cd "$BACKUP_DIR"
    tar -czf "${BACKUP_NAME}.tar.gz" ${BACKUP_NAME}*.sql ${BACKUP_NAME}*.txt 2>/dev/null || true
    
    # ‰∏ä‰º†Âà∞‰∫ëÂ≠òÂÇ®
    log "‰∏ä‰º†Â§á‰ªΩÂà∞‰∫ëÂ≠òÂÇ®..."
    aws s3 cp "${BACKUP_NAME}.tar.gz" "s3://${S3_BUCKET}/database/" \
        --storage-class "$S3_STORAGE_CLASS" \
        --metadata "backup-type=database,backup-date=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
    
    # Ê∏ÖÁêÜÊú¨Âú∞Â§á‰ªΩÊñá‰ª∂
    rm -f ${BACKUP_NAME}*
    
    log "SupabaseÊï∞ÊçÆÂ∫ìÂ§á‰ªΩÂÆåÊàê: ${BACKUP_NAME}.tar.gz"

  # KubernetesÈÖçÁΩÆÂ§á‰ªΩËÑöÊú¨
  backup-k8s-config.sh: |
    #!/bin/bash
    set -euo pipefail
    
    BACKUP_NAME="k8s-config-backup-$(date +%Y%m%d-%H%M%S)"
    BACKUP_DIR="/tmp/backups"
    
    log() {
        echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
    }
    
    mkdir -p "$BACKUP_DIR/$BACKUP_NAME"
    
    log "ÂºÄÂßãKubernetesÈÖçÁΩÆÂ§á‰ªΩ..."
    
    # Â§á‰ªΩÊâÄÊúâConfigMaps
    log "Â§á‰ªΩConfigMaps..."
    kubectl get configmaps --all-namespaces -o yaml > "$BACKUP_DIR/$BACKUP_NAME/configmaps.yaml"
    
    # Â§á‰ªΩÊâÄÊúâSecretsÔºàÊïèÊÑü‰ø°ÊÅØÂ∞ÜË¢´Âä†ÂØÜÂ≠òÂÇ®Ôºâ
    log "Â§á‰ªΩSecrets..."
    kubectl get secrets --all-namespaces -o yaml > "$BACKUP_DIR/$BACKUP_NAME/secrets.yaml"
    
    # Â§á‰ªΩDeployments
    log "Â§á‰ªΩDeployments..."
    kubectl get deployments --all-namespaces -o yaml > "$BACKUP_DIR/$BACKUP_NAME/deployments.yaml"
    
    # Â§á‰ªΩServices
    log "Â§á‰ªΩServices..."
    kubectl get services --all-namespaces -o yaml > "$BACKUP_DIR/$BACKUP_NAME/services.yaml"
    
    # Â§á‰ªΩIngress
    log "Â§á‰ªΩIngress..."
    kubectl get ingress --all-namespaces -o yaml > "$BACKUP_DIR/$BACKUP_NAME/ingress.yaml"
    
    # Â§á‰ªΩPersistentVolumesÂíåPersistentVolumeClaims
    log "Â§á‰ªΩÂ≠òÂÇ®ÈÖçÁΩÆ..."
    kubectl get pv -o yaml > "$BACKUP_DIR/$BACKUP_NAME/persistent-volumes.yaml"
    kubectl get pvc --all-namespaces -o yaml > "$BACKUP_DIR/$BACKUP_NAME/persistent-volume-claims.yaml"
    
    # Â§á‰ªΩStatefulSets
    log "Â§á‰ªΩStatefulSets..."
    kubectl get statefulsets --all-namespaces -o yaml > "$BACKUP_DIR/$BACKUP_NAME/statefulsets.yaml"
    
    # Â§á‰ªΩËá™ÂÆö‰πâËµÑÊ∫ê
    log "Â§á‰ªΩËá™ÂÆö‰πâËµÑÊ∫ê..."
    kubectl get crd -o yaml > "$BACKUP_DIR/$BACKUP_NAME/custom-resources.yaml"
    
    # Â§á‰ªΩÁΩëÁªúÁ≠ñÁï•
    log "Â§á‰ªΩÁΩëÁªúÁ≠ñÁï•..."
    kubectl get networkpolicies --all-namespaces -o yaml > "$BACKUP_DIR/$BACKUP_NAME/network-policies.yaml"
    
    # ÂàõÂª∫Â§á‰ªΩÊ∏ÖÂçï
    cat > "$BACKUP_DIR/$BACKUP_NAME/backup-manifest.yaml" <<EOF
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: backup-manifest
      namespace: backup
    data:
      backup-date: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
      backup-name: "$BACKUP_NAME"
      kubernetes-version: "$(kubectl version --short --client | grep Client | cut -d' ' -f3)"
      cluster-info: |
    $(kubectl cluster-info | sed 's/^/    /')
    EOF
    
    # ÂéãÁº©Â§á‰ªΩ
    log "ÂéãÁº©Â§á‰ªΩÊñá‰ª∂..."
    cd "$BACKUP_DIR"
    tar -czf "${BACKUP_NAME}.tar.gz" "$BACKUP_NAME/"
    
    # ‰∏ä‰º†Âà∞‰∫ëÂ≠òÂÇ®
    log "‰∏ä‰º†ÈÖçÁΩÆÂ§á‰ªΩÂà∞‰∫ëÂ≠òÂÇ®..."
    aws s3 cp "${BACKUP_NAME}.tar.gz" "s3://${S3_BUCKET}/kubernetes-config/" \
        --storage-class "$S3_STORAGE_CLASS" \
        --metadata "backup-type=kubernetes-config,backup-date=$(date -u +%Y-%m-%dT%H:%M:%SZ)"
    
    # Ê∏ÖÁêÜÊú¨Âú∞Êñá‰ª∂
    rm -rf "$BACKUP_NAME" "${BACKUP_NAME}.tar.gz"
    
    log "KubernetesÈÖçÁΩÆÂ§á‰ªΩÂÆåÊàê: ${BACKUP_NAME}.tar.gz"

  # Â∫îÁî®Êï∞ÊçÆÂ§á‰ªΩËÑöÊú¨
  backup-app-data.sh: |
    #!/bin/bash
    set -euo pipefail
    
    BACKUP_NAME="app-data-backup-$(date +%Y%m%d-%H%M%S)"
    BACKUP_DIR="/tmp/backups"
    
    log() {
        echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
    }
    
    mkdir -p "$BACKUP_DIR"
    
    log "ÂºÄÂßãÂ∫îÁî®Êï∞ÊçÆÂ§á‰ªΩ..."
    
    # Â§á‰ªΩÂ∫îÁî®‰∏ä‰º†ÁöÑÊñá‰ª∂
    log "Â§á‰ªΩÂ∫îÁî®Êñá‰ª∂Êï∞ÊçÆ..."
    if kubectl get pvc app-data-pvc -n production &>/dev/null; then
        kubectl exec -n production deployment/figma-frame-faithful -- tar -czf - /app/uploads 2>/dev/null | \
            aws s3 cp - "s3://${S3_BUCKET}/app-data/${BACKUP_NAME}-uploads.tar.gz" \
            --storage-class "$S3_STORAGE_CLASS"
    fi
    
    # Â§á‰ªΩÂ∫îÁî®ÈÖçÁΩÆÊñá‰ª∂
    log "Â§á‰ªΩÂ∫îÁî®ÈÖçÁΩÆ..."
    kubectl get configmap app-config -n production -o yaml > "$BACKUP_DIR/${BACKUP_NAME}-app-config.yaml"
    kubectl get secret app-secrets -n production -o yaml > "$BACKUP_DIR/${BACKUP_NAME}-app-secrets.yaml"
    
    # Â§á‰ªΩÁî®Êà∑‰ºöËØùÊï∞ÊçÆÔºàÂ¶ÇÊûú‰ΩøÁî®RedisÔºâ
    if kubectl get service redis -n production &>/dev/null; then
        log "Â§á‰ªΩRedis‰ºöËØùÊï∞ÊçÆ..."
        kubectl exec -n production service/redis -- redis-cli BGSAVE
        sleep 5  # Á≠âÂæÖÂ§á‰ªΩÂÆåÊàê
        kubectl cp production/redis-pod:/data/dump.rdb "$BACKUP_DIR/${BACKUP_NAME}-redis-dump.rdb"
    fi
    
    # ÂéãÁº©Êú¨Âú∞Â§á‰ªΩÊñá‰ª∂
    if [[ -f "$BACKUP_DIR/${BACKUP_NAME}-app-config.yaml" ]]; then
        cd "$BACKUP_DIR"
        tar -czf "${BACKUP_NAME}-config.tar.gz" ${BACKUP_NAME}*.yaml ${BACKUP_NAME}*.rdb 2>/dev/null || true
        
        # ‰∏ä‰º†ÈÖçÁΩÆÂ§á‰ªΩ
        aws s3 cp "${BACKUP_NAME}-config.tar.gz" "s3://${S3_BUCKET}/app-data/" \
            --storage-class "$S3_STORAGE_CLASS"
        
        # Ê∏ÖÁêÜÊú¨Âú∞Êñá‰ª∂
        rm -f ${BACKUP_NAME}*
    fi
    
    log "Â∫îÁî®Êï∞ÊçÆÂ§á‰ªΩÂÆåÊàê"

  # ÁõëÊéßÊï∞ÊçÆÂ§á‰ªΩËÑöÊú¨
  backup-monitoring.sh: |
    #!/bin/bash
    set -euo pipefail
    
    BACKUP_NAME="monitoring-backup-$(date +%Y%m%d-%H%M%S)"
    BACKUP_DIR="/tmp/backups"
    
    log() {
        echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
    }
    
    mkdir -p "$BACKUP_DIR/$BACKUP_NAME"
    
    log "ÂºÄÂßãÁõëÊéßÊï∞ÊçÆÂ§á‰ªΩ..."
    
    # Â§á‰ªΩPrometheusÊï∞ÊçÆ
    if kubectl get statefulset prometheus -n monitoring &>/dev/null; then
        log "ÂàõÂª∫PrometheusÊï∞ÊçÆÂø´ÁÖß..."
        kubectl exec -n monitoring statefulset/prometheus -- \
            curl -XPOST http://localhost:9090/api/v1/admin/tsdb/snapshot
        
        # Ëé∑ÂèñÊúÄÊñ∞Âø´ÁÖß
        SNAPSHOT=$(kubectl exec -n monitoring statefulset/prometheus -- \
            ls -t /prometheus/snapshots/ | head -1)
        
        if [[ -n "$SNAPSHOT" ]]; then
            log "Â§á‰ªΩPrometheusÂø´ÁÖß: $SNAPSHOT"
            kubectl exec -n monitoring statefulset/prometheus -- \
                tar -czf - -C /prometheus/snapshots "$SNAPSHOT" | \
                aws s3 cp - "s3://${S3_BUCKET}/monitoring/prometheus-${BACKUP_NAME}.tar.gz" \
                --storage-class "$S3_STORAGE_CLASS"
        fi
    fi
    
    # Â§á‰ªΩGrafanaÈÖçÁΩÆ
    if kubectl get deployment grafana -n monitoring &>/dev/null; then
        log "Â§á‰ªΩGrafanaÈÖçÁΩÆ..."
        kubectl get configmap grafana-config -n monitoring -o yaml > "$BACKUP_DIR/$BACKUP_NAME/grafana-config.yaml"
        kubectl get configmap grafana-dashboards -n monitoring -o yaml > "$BACKUP_DIR/$BACKUP_NAME/grafana-dashboards.yaml"
    fi
    
    # Â§á‰ªΩAlertManagerÈÖçÁΩÆ
    if kubectl get deployment alertmanager -n monitoring &>/dev/null; then
        log "Â§á‰ªΩAlertManagerÈÖçÁΩÆ..."
        kubectl get configmap alertmanager-config -n monitoring -o yaml > "$BACKUP_DIR/$BACKUP_NAME/alertmanager-config.yaml"
    fi
    
    # Â§á‰ªΩElasticsearchÂø´ÁÖß
    if kubectl get statefulset elasticsearch-master -n logging &>/dev/null; then
        log "ÂàõÂª∫ElasticsearchÂø´ÁÖß..."
        
        # ÂàõÂª∫Âø´ÁÖß‰ªìÂ∫ìÔºàÂ¶ÇÊûú‰∏çÂ≠òÂú®Ôºâ
        kubectl exec -n logging statefulset/elasticsearch-master -- \
            curl -X PUT "localhost:9200/_snapshot/backup_repository" \
            -H 'Content-Type: application/json' \
            -d '{
              "type": "fs",
              "settings": {
                "location": "/backup",
                "compress": true
              }
            }' || true
        
        # ÂàõÂª∫Âø´ÁÖß
        kubectl exec -n logging statefulset/elasticsearch-master -- \
            curl -X PUT "localhost:9200/_snapshot/backup_repository/snapshot-${BACKUP_NAME}" \
            -H 'Content-Type: application/json' \
            -d '{
              "indices": "*",
              "ignore_unavailable": true,
              "include_global_state": false
            }'
    fi
    
    # ÂéãÁº©Âπ∂‰∏ä‰º†ÈÖçÁΩÆÊñá‰ª∂
    if [[ -d "$BACKUP_DIR/$BACKUP_NAME" ]] && [[ -n "$(ls -A "$BACKUP_DIR/$BACKUP_NAME" 2>/dev/null)" ]]; then
        cd "$BACKUP_DIR"
        tar -czf "${BACKUP_NAME}-config.tar.gz" "$BACKUP_NAME/"
        
        aws s3 cp "${BACKUP_NAME}-config.tar.gz" "s3://${S3_BUCKET}/monitoring/" \
            --storage-class "$S3_STORAGE_CLASS"
        
        rm -rf "$BACKUP_NAME" "${BACKUP_NAME}-config.tar.gz"
    fi
    
    log "ÁõëÊéßÊï∞ÊçÆÂ§á‰ªΩÂÆåÊàê"

---
# üîê ServiceAccount - Â§á‰ªΩÁ≥ªÁªü
apiVersion: v1
kind: ServiceAccount
metadata:
  name: backup-service
  namespace: backup
  labels:
    app: backup-system

---
# üîë ClusterRole - Â§á‰ªΩÊùÉÈôê
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: backup-cluster-role
  labels:
    app: backup-system
rules:
# ËØªÂèñÊâÄÊúâËµÑÊ∫êÁî®‰∫éÂ§á‰ªΩ
- apiGroups: [""]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["extensions", "networking.k8s.io"]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["storage.k8s.io"]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apiextensions.k8s.io"]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
# ExecÊùÉÈôêÁî®‰∫éÊâßË°åÂ§á‰ªΩÂëΩ‰ª§
- apiGroups: [""]
  resources: ["pods/exec"]
  verbs: ["create"]
# Âø´ÁÖßÂàõÂª∫ÊùÉÈôê
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]
  resourceNames: ["prometheus-*", "elasticsearch-*"]

---
# üîó ClusterRoleBinding - Â§á‰ªΩÊùÉÈôêÁªëÂÆö
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: backup-cluster-role-binding
  labels:
    app: backup-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: backup-cluster-role
subjects:
- kind: ServiceAccount
  name: backup-service
  namespace: backup

---
# üîê Secret - AWSÂá≠ËØÅ
apiVersion: v1
kind: Secret
metadata:
  name: aws-credentials
  namespace: backup
  labels:
    app: backup-system
type: Opaque
data:
  # ËØ∑ÊõøÊç¢‰∏∫ÂÆûÈôÖÁöÑbase64ÁºñÁ†ÅÁöÑAWSÂá≠ËØÅ
  AWS_ACCESS_KEY_ID: WU9VUl9BV1NfQUNDRVNTX0tFWV9JRA==  # YOUR_AWS_ACCESS_KEY_ID
  AWS_SECRET_ACCESS_KEY: WU9VUl9BV1NfU0VDUkVUX0FDQ0VTU19LRVk=  # YOUR_AWS_SECRET_ACCESS_KEY
  AWS_DEFAULT_REGION: dXMtZWFzdC0x  # us-east-1

---
# üîê Secret - ÈÄöÁü•ÈÖçÁΩÆ
apiVersion: v1
kind: Secret
metadata:
  name: backup-notifications
  namespace: backup
  labels:
    app: backup-system
type: Opaque
data:
  SLACK_WEBHOOK_URL: aHR0cHM6Ly9ob29rcy5zbGFjay5jb20vc2VydmljZXMvWU9VUi9TTEFDS1dFQkhPT0s=  # https://hooks.slack.com/services/YOUR/SLACKWEBHOOK
  EMAIL_SMTP_PASSWORD: WU9VUl9FTUFJTF9QQVNTV09SRA==  # YOUR_EMAIL_PASSWORD